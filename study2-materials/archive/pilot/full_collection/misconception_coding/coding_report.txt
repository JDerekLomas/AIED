================================================================================
MISCONCEPTION CODING REPORT
Study 2: LLM Synthetic Student Misconception Alignment
================================================================================

## 1. OVERVIEW
Total errors coded: 208
Target distractor hits: 104 (50.0%)

Auto-coding breakdown:
  DIFFERENT_ERROR: 96 (46.2%)
  FULL_MATCH: 1 (0.5%)
  PARTIAL_MATCH: 17 (8.2%)
  UNCLEAR: 94 (45.2%)

## 2. KEY FINDING: MISCONCEPTION ALIGNMENT
Errors with reasoning matching target misconception: 18/208 (8.7%)
  - Full match: 1 (0.5%)
  - Partial match: 17 (8.2%)

Comparison to target distractor rate: 50.0%
Gap (distractor - misconception): 41.3 percentage points

## 3. BY MODEL
------------------------------------------------------------
mistral-7b:
  Errors: 78
  Target distractor rate: 46.2%
  Misconception alignment: 16.7% (full: 1.3%, partial: 15.4%)

gpt-3.5-turbo:
  Errors: 25
  Target distractor rate: 76.0%
  Misconception alignment: 4.0% (full: 0.0%, partial: 4.0%)

claude-3-haiku:
  Errors: 20
  Target distractor rate: 50.0%
  Misconception alignment: 0.0% (full: 0.0%, partial: 0.0%)

claude-3.5-sonnet:
  Errors: 2
  Target distractor rate: 100.0%
  Misconception alignment: 0.0% (full: 0.0%, partial: 0.0%)

llama-3.1-8b-groq:
  Errors: 20
  Target distractor rate: 50.0%
  Misconception alignment: 10.0% (full: 0.0%, partial: 10.0%)

llama-3.2-3b-together:
  Errors: 63
  Target distractor rate: 42.9%
  Misconception alignment: 3.2% (full: 0.0%, partial: 3.2%)

## 4. BY CONDITION
------------------------------------------------------------
answer_only: 115 errors, target=52.2%, full_match=0.9%
explain: 37 errors, target=78.4%, full_match=0.0%
persona: 56 errors, target=26.8%, full_match=0.0%

## 5. BY MISCONCEPTION TYPE
------------------------------------------------------------
PROC_NEGATIVE_SUBTRACT: 27 errors, target=40.7%, full_match=3.7%
CONC_MULT_INCREASE: 20 errors, target=50.0%, full_match=0.0%
CONC_PERCENT_BASE: 12 errors, target=33.3%, full_match=0.0%
PROC_ALGEBRA_COMBINE: 16 errors, target=18.8%, full_match=0.0%
CONC_FRAC_DENOM: 23 errors, target=78.3%, full_match=0.0%
INTERP_GRAPH_AXES: 9 errors, target=22.2%, full_match=0.0%
PROC_ORDER_OPS: 29 errors, target=20.7%, full_match=0.0%
PROC_DECIMAL_PLACE: 21 errors, target=66.7%, full_match=0.0%
PROC_SUBTRACT_REVERSE: 31 errors, target=74.2%, full_match=0.0%
CONC_AREA_PERIMETER: 20 errors, target=65.0%, full_match=0.0%

## 6. SAMPLE CODED ERRORS (for manual verification)
------------------------------------------------------------

### FULL_MATCH Examples:

Item: PROC_NEGATIVE_SUBTRACT_03
Model: mistral-7b | Condition: answer_only
Target misconception: Treats subtraction of negative as addition of positive or vice versa
Answer: A (correct: B, target: A)
Target hit: True
Reasoning: **
Calculate: 10 - (-2) - 3

A) 5
(First, subtract the negative number: 10 - (-2) = 12. Then subtract 3: 12 - 3 = 9. However, the question asks for 10 - (-2) - 3, which equals 12 - 2 - 3 = 5.)...
Evidence: Multiple indicators: ['subtract.*negative.*subtract', '-.*-.*=.*-']


### PARTIAL_MATCH Examples:

Item: PROC_ORDER_OPS_01
Model: mistral-7b | Condition: answer_only
Target misconception: Carries out operations from left to right regardless of priority order
Answer: D (correct: B, target: A)
Target hit: False
Reasoning: **
Calculate: 5 + 3 × 2

A) 16 (Incorrect. This would be the sum of 5 and 16, but we need to do the multiplication first.)
B) 11 (Incorrect.)
C) 13 (Incorrect.)
D) 10 (Correct. First, perform the multiplication: 3 * 2 = 6, then add 5: 6 + 5 = 10)...
Evidence: Single indicator: 5.*\+.*3.*=.*8.*then|first.*add


Item: PROC_NEGATIVE_SUBTRACT_02
Model: mistral-7b | Condition: answer_only
Target misconception: Treats subtraction of negative as addition of positive or vice versa
Answer: D (correct: B, target: A)
Target hit: False
Reasoning: **
What is -4 - (-6)?

A) -10 (Correct. -4 - (-6) = 4 + 6 = 10, but the answer should be negative because the initial -4 is negative.)
B) 2 (Incorrect.)
C) -2 (Incorrect.)
D) 10 (Incorrect.)...
Evidence: Single indicator: -.*-.*=.*-


### DIFFERENT_ERROR Examples:

Item: PROC_NEGATIVE_SUBTRACT_03
Model: mistral-7b | Condition: answer_only
Target misconception: Treats subtraction of negative as addition of positive or vice versa
Answer: C (correct: B, target: A)
Target hit: False
Reasoning: ** Here, we have 10 - (-2) - 3. First, we calculate -2 and change it to a positive number, which is 2. Then, we subtract 2 from 10 and add 3, giving us 15. The correct answer is C) 15....
Evidence: Has reasoning but no misconception indicators


Item: CONC_MULT_INCREASE_01
Model: mistral-7b | Condition: answer_only
Target misconception: Believes multiplying always makes the number bigger
Answer: A (correct: B, target: A)
Target hit: True
Reasoning: ** Multiplying 8 by 0.5 gives us 4, which is smaller than 8. The correct answer is A) 8....
Evidence: Has reasoning but no misconception indicators


### UNCLEAR Examples:

Item: PROC_SUBTRACT_REVERSE_04
Model: mistral-7b | Condition: answer_only
Target misconception: Subtracts smaller digit from larger in each column regardless of position
Answer: A (correct: B, target: A)
Target hit: True
Reasoning: ** What is 64 - 38?

A) 34...
Evidence: Minimal reasoning


Item: PROC_ALGEBRA_COMBINE_05
Model: mistral-7b | Condition: answer_only
Target misconception: Combines unlike terms as if they were like terms
Answer: A (correct: B, target: A)
Target hit: True
Reasoning: ** Simplify: x + x²

A) x + x²...
Evidence: Minimal reasoning
